\item \subquestionpoints{10} Recall that the principal component is the largest eigenvalue of $X^\top X$ for data matrix $X \in R^{n \times d}$. Show that the unit-length vector $u$ that minimizes the 
mean squared error between projected points and original points corresponds
to the first principal component for the data. I.e., show that
$$ \arg \min_{u:u^Tu=1} \sum_{i=1}^\nexp \|x^{(i)}-f_u(x^{(i)})\|_2^2 \ .$$
gives the first principal component.


{\bf Remark.} If we are asked to find a $k$-dimensional subspace onto which to
project the data so as to minimize the sum of squares distance between the
original data and their projections, then we should choose the $k$-dimensional
subspace spanned by the first $k$ principal components of the data.  This problem
shows that this result holds for the case of $k=1$.