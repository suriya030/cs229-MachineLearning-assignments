\item \subquestionpoints{15} 
Now letâ€™s implement a classification, univariate decision tree with misclassification loss (mentioned in Equation 1). The starter code is provided in 

\texttt{src/decision\_trees\_general/decision\_tree.py}. Fill in the functions marked with \texttt{\#TODO}. You are not allowed to use any package other than \texttt{NumPy}. You cannot assume there are only two classes. Report the accuracy output when running the Python script. For reference, the 
staff solution gives the same expected accuracy in part (a) for the college degree dataset (Table 1) 
and $93.33\%$ for the iris dataset.